{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshwinPradeep01/Cancer-lesion-prediction/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the Kaggle API To Import the Dataset**"
      ],
      "metadata": {
        "id": "vxi9dk2vhQES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install -q kaggle"
      ],
      "metadata": {
        "id": "Ga-gXeSTEXFN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " ! mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "4mWyqZb_K303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa83ebf5-7580-4d02-ce5f-935b2e3cde81"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "7eYqJ5dwGyMl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "qAC8azpbGyJ6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download gauravduttakiit/mammography-breast-cancer-detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERVoGC5gGyBT",
        "outputId": "c15d1a96-5514-4970-8439-c4dccf8f8869"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading mammography-breast-cancer-detection.zip to /content\n",
            " 99% 992M/0.98G [00:09<00:00, 123MB/s]\n",
            "100% 0.98G/0.98G [00:09<00:00, 109MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Unzipping the image data**"
      ],
      "metadata": {
        "id": "ydlyW_Aohb0z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip /content/mammography-breast-cancer-detection.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-05DPmxLsj5",
        "outputId": "70ca110e-cfb4-469e-f4a8-1097d3469f03"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/mammography-breast-cancer-detection.zip\n",
            "replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! kaggle datasets download skooch/ddsm-mammography"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jpUwdJujndX",
        "outputId": "d229634d-3e2c-4581-fc16-f457cd098161"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ddsm-mammography.zip to /content\n",
            "100% 2.88G/2.88G [00:18<00:00, 45.5MB/s]\n",
            "100% 2.88G/2.88G [00:18<00:00, 169MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/ddsm-mammography.zip"
      ],
      "metadata": {
        "id": "p83yG6Y-Teu7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b126422-8ec4-4c17-f6fa-10fb750b9a5c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/ddsm-mammography.zip\n",
            "  inflating: cv10_data/cv10_data.npy  \n",
            "  inflating: cv10_labels.npy         \n",
            "  inflating: test10_data/test10_data.npy  \n",
            "  inflating: test10_labels.npy       \n",
            "  inflating: training10_0/training10_0.tfrecords  \n",
            "  inflating: training10_1/training10_1.tfrecords  \n",
            "  inflating: training10_2/training10_2.tfrecords  \n",
            "  inflating: training10_3/training10_3.tfrecords  \n",
            "  inflating: training10_4/training10_4.tfrecords  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YnIusC5gTB-",
        "outputId": "32ddee81-ac57-474b-ce6f-59757a7548c2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting preprocessing\n",
            "  Downloading preprocessing-0.1.13-py3-none-any.whl (349 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.6/349.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.2.4 (from preprocessing)\n",
            "  Downloading nltk-3.2.4.tar.gz (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sphinx-rtd-theme==0.2.4 (from preprocessing)\n",
            "  Downloading sphinx_rtd_theme-0.2.4-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from nltk==3.2.4->preprocessing) (1.16.0)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.2.4-py3-none-any.whl size=1367707 sha256=4a2673312b018e3f7bfb65f39e990f5913fababd35be5ed861f0941b04773c39\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/8c/42/bcd0934b61ecf4cef964ccc9881888cca0841ec72266e99de1\n",
            "Successfully built nltk\n",
            "Installing collected packages: sphinx-rtd-theme, nltk, preprocessing\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "Successfully installed nltk-3.2.4 preprocessing-0.1.13 sphinx-rtd-theme-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing the Required Libraries**"
      ],
      "metadata": {
        "id": "k-QeISzLhkNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "from tensorflow.keras.losses import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "from tensorflow.keras.preprocessing.image import *\n",
        "from tensorflow.keras.utils import *\n",
        "from sklearn.metrics import *\n",
        "from collections import Counter\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import preprocessing\n",
        "from tqdm import tqdm\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "from os import listdir\n",
        "import matplotlib.pyplot as plt\n",
        "from imageio import imread\n",
        "from skimage.transform import resize\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.model_selection import *"
      ],
      "metadata": {
        "id": "XOqnNaEjLtAl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from glob import glob\n",
        "from skimage.io import *\n",
        "%config Completer.use_jedi = False\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"All modules have been imported\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5OGYMh-gVvt",
        "outputId": "705fcc99-6964-491e-bab7-7ec077a125fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All modules have been imported\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Structure for the data"
      ],
      "metadata": {
        "id": "hITL3aM2ht0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images=[]\n",
        "labels=[]\n",
        "feature_dictionary = {\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image': tf.io.FixedLenFeature([], tf.string)\n",
        "    }"
      ],
      "metadata": {
        "id": "e5P77bVMgX9T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize = (6,6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=90)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    cm = np.round(cm,2)\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "xtz56Rokgamm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _parse_function(example, feature_dictionary=feature_dictionary):\n",
        "    parsed_example = tf.io.parse_example(example, feature_dictionary)\n",
        "    return parsed_example"
      ],
      "metadata": {
        "id": "6h8KNswlgdJS"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Reading the Data**"
      ],
      "metadata": {
        "id": "BKtMNrAIiXUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(filename):\n",
        "    full_dataset = tf.data.TFRecordDataset(filename,num_parallel_reads=tf.data.experimental.AUTOTUNE)\n",
        "    full_dataset = full_dataset.cache()\n",
        "    print(\"Size of Training Dataset: \", len(list(full_dataset)))\n",
        "\n",
        "    feature_dictionary = {\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'label_normal': tf.io.FixedLenFeature([], tf.int64),\n",
        "    'image': tf.io.FixedLenFeature([], tf.string)\n",
        "    }\n",
        "\n",
        "    full_dataset = full_dataset.map(_parse_function, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    print(full_dataset)\n",
        "    for image_features in full_dataset:\n",
        "        image = image_features['image'].numpy()\n",
        "        image = tf.io.decode_raw(image_features['image'], tf.uint8)\n",
        "        image = tf.reshape(image, [299, 299])\n",
        "        image=image.numpy()\n",
        "        image=cv2.resize(image,(100,100))\n",
        "        image=cv2.merge([image,image,image])\n",
        "        image\n",
        "        images.append(image)\n",
        "        labels.append(image_features['label_normal'].numpy())"
      ],
      "metadata": {
        "id": "aJptxk-0gek2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Files names stored in tensorflowrecords format and Reading Them**"
      ],
      "metadata": {
        "id": "HnHRpH0QidYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filenames=[\n",
        "    '/content/training10_0/training10_0.tfrecords',\n",
        "    '/content/training10_1/training10_1.tfrecords',\n",
        "    '/content/training10_2/training10_2.tfrecords',\n",
        "    # '/content/training10_3/training10_3.tfrecords',\n",
        "#     '/kaggle/input/ddsm-mammography/training10_4/training10_4.tfrecords'\n",
        "          ]\n",
        "\n",
        "\n",
        "\n",
        "for file in filenames:\n",
        "    read_data(file)\n",
        "\n",
        "print(len(images))\n",
        "print(len(labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdikW33hghL5",
        "outputId": "87964e0e-8b8f-4f7f-db2a-620d26df91ec"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of Training Dataset:  11177\n",
            "<_ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
            "Size of Training Dataset:  11177\n",
            "<_ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
            "Size of Training Dataset:  11177\n",
            "<_ParallelMapDataset element_spec={'image': TensorSpec(shape=(), dtype=tf.string, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'label_normal': TensorSpec(shape=(), dtype=tf.int64, name=None)}>\n",
            "33531\n",
            "33531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Splitting the dataset into the Training and the Testing set**"
      ],
      "metadata": {
        "id": "7s8NxdDWh-WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.array(images)\n",
        "y=np.array(labels)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n",
        "                                                    random_state=0,\n",
        "                                                    shuffle=True,\n",
        "                                                    stratify=y)"
      ],
      "metadata": {
        "id": "FbJhqolWgmIG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from sklearn import metrics\n",
        "\n",
        "print(x_train[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y42ZygcCgodU",
        "outputId": "a47b81a2-0e92-456e-d677-850a23f9b913"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 100, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Defining the network design**"
      ],
      "metadata": {
        "id": "X8iGaQpNipvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = ResNet50(input_shape=(100,100,3), weights='imagenet', include_top=False)\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# model.add(Activation('relu'))\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMTkfN3qgrQZ",
        "outputId": "f0511805-88fd-40a6-e4d8-1b0c691b0ab0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 32768)             0         \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32768)             131072    \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1048608   \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24767553 (94.48 MB)\n",
            "Trainable params: 24648833 (94.03 MB)\n",
            "Non-trainable params: 118720 (463.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setting up the callbacks"
      ],
      "metadata": {
        "id": "6lhE3ogsiyyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c1= tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=3, verbose=1)\n",
        "c2=tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.1,\n",
        "    patience=2,\n",
        "    mode=\"auto\",\n",
        "    min_delta=0.0001,\n",
        "    cooldown=0,\n",
        "    min_lr=0.001)"
      ],
      "metadata": {
        "id": "dsedcp8Lgu1Z"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Fitting the data in the model and training**"
      ],
      "metadata": {
        "id": "EdJsJPeRi4c5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy','AUC'])"
      ],
      "metadata": {
        "id": "zrNduVjSkg9V"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train,validation_split=0.2,epochs=10, batch_size=128,callbacks=[c1,c2],class_weight={0:0.7,1:1})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MB81rABXgxJy",
        "outputId": "a0b429d2-6e61-4250-ff3b-b578e094a933"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "147/147 [==============================] - 116s 387ms/step - loss: 0.0000e+00 - accuracy: 0.8447 - auc: 0.9118 - val_loss: 0.0000e+00 - val_accuracy: 0.5091 - val_auc: 0.6806 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "147/147 [==============================] - 53s 363ms/step - loss: 0.0000e+00 - accuracy: 0.8921 - auc: 0.9112 - val_loss: 0.0000e+00 - val_accuracy: 0.6596 - val_auc: 0.7162 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "147/147 [==============================] - 52s 351ms/step - loss: 0.0000e+00 - accuracy: 0.9069 - auc: 0.9008 - val_loss: 0.0000e+00 - val_accuracy: 0.3419 - val_auc: 0.6234 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "147/147 [==============================] - 53s 361ms/step - loss: 0.0000e+00 - accuracy: 0.9200 - auc: 0.9001 - val_loss: 0.0000e+00 - val_accuracy: 0.7099 - val_auc: 0.7117 - lr: 0.0010\n",
            "Epoch 4: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(x_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1sdUXMrgt8A",
        "outputId": "f794aed4-a047-48c7-8d86-d775422e9d32"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "315/315 [==============================] - 11s 29ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "target=[\"0\",\"1\"]\n",
        "from sklearn import metrics\n",
        "print('Accuracy:', np.round(metrics.accuracy_score(y_test, y_pred_classes),5))\n",
        "print('Precision:', np.round(metrics.precision_score(y_test, y_pred_classes, average='weighted'),5))\n",
        "print('Recall:', np.round(metrics.recall_score(y_test,y_pred_classes, average='weighted'),5))\n",
        "print('F1 Score:', np.round(metrics.f1_score(y_test, y_pred_classes, average='weighted'),5))\n",
        "print('ROC AUC Score:', np.round(metrics.roc_auc_score(y_test, y_pred_classes,multi_class='ovo', average='weighted'),5))\n",
        "print('\\t\\tClassification Report:\\n', metrics.classification_report(y_test, y_pred_classes,target_names=target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvkohQplg0J5",
        "outputId": "74c5de82-9d01-4a27-9162-a9067c3d31d3"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.87078\n",
            "Precision: 0.75825\n",
            "Recall: 0.87078\n",
            "F1 Score: 0.81063\n",
            "ROC AUC Score: 0.5\n",
            "\t\tClassification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93      8760\n",
            "           1       0.00      0.00      0.00      1300\n",
            "\n",
            "    accuracy                           0.87     10060\n",
            "   macro avg       0.44      0.50      0.47     10060\n",
            "weighted avg       0.76      0.87      0.81     10060\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **SAving the model**"
      ],
      "metadata": {
        "id": "T1ijKvSNi-95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/res50_model.h5')"
      ],
      "metadata": {
        "id": "jCzHV7kdhJP6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading the model**"
      ],
      "metadata": {
        "id": "IikDEHnZjI6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model(r\"/content/res50_model.h5\")"
      ],
      "metadata": {
        "id": "3h-ayFapiM7h"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J-N77CdAj5-u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}